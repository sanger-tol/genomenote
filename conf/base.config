/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    sanger-tol/genomenote Nextflow base config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

process {

    errorStrategy = { task.exitStatus in ((130..145) + 104) ? 'retry' : 'finish' }
    maxRetries    = 5
    maxErrors     = '-1'

    // In this configuration file, we give little resources by default and
    // explicitly bump them up for some processes.
    // All rules should still increase resources every attempt to allow the
    // pipeline to self-heal from MEMLIMIT/RUNLIMIT.

    // Default
    cpus   = 1
    memory = { check_max( 50.MB * task.attempt, 'memory' ) }
    time   = { check_max( 30.min * task.attempt, 'time' ) }

    // These processes typically complete within 30 min to 1.5 hours.
    withName: 'BED_SORT|BEDTOOLS_BAMTOBED|COOLER_CLOAD|COOLER_ZOOMIFY|FILTER_BED' {
        time   = { check_max( 4.hour * task.attempt, 'time' ) }
    }

    // These processes may take a few hours.
    withName: 'FILTER_SORT|SAMTOOLS_VIEW' {
        time   = { check_max( 8.hour * task.attempt, 'time' ) }
    }

    withName: SAMTOOLS_VIEW {
        memory = { check_max( 1.GB  * task.attempt, 'memory'  ) }
    }

    withName: GFASTATS {
        memory = { check_max( 1.GB * 1.2 * Math.ceil(meta.genome_size/1e9) * task.attempt, 'memory' ) }
    }

    withName: FASTK_FASTK {
        memory = { check_max( 12.GB * task.attempt, 'memory'  ) }
        cpus   = { log_increase_cpus(4, 2*task.attempt, 1, 2) }
    }

    withName: MERQURYFK_MERQURYFK {
        time   = { check_max( 10.min * Math.ceil(meta.genome_size/1000000000) * task.attempt, 'time') }
        // Memory usage is probably correlated to the diversity of k-mers found
        // in the assembly, which grows with the genome size but then plateaus.
        // The memory is increased by half of the base value at every attempt.
        memory = { check_max( (
                        meta.genome_size <  100000000 ?  6.GB :
                        meta.genome_size <  500000000 ? 12.GB : 24.GB
                    ) * ((task.attempt+1)/2) , 'memory' ) }
        cpus   = { log_increase_cpus(4, 2*task.attempt, 1, 2) }
    }

    withName: FASTK_HISTEX {
        memory = { check_max( 100.MB * task.attempt, 'memory'  ) }
    }

    withName: GENESCOPEFK {
        memory = { check_max( 400.MB * task.attempt, 'memory'  ) }
    }

    withName: BUSCO {
        // The formulas below are equivalent to these ranges:
        // Gbp:    [ 1,  2,  4,   8,  16]
        // CPUs:   [ 8, 12, 16,  20,  24]
        // GB RAM: [16, 32, 64, 128, 256]
        memory = { check_max( 1.GB * Math.pow(2, 3 + task.attempt + Math.ceil(positive_log(meta.genome_size/1000000000, 2))) , 'memory' ) }
        cpus   = { log_increase_cpus(4, 4*task.attempt, Math.ceil(meta.genome_size/1000000000), 2) }
        time   = { check_max( 3.h * Math.ceil(meta.genome_size/1000000000) * task.attempt, 'time') }
    }

    withName: 'BED_SORT|FILTER_SORT' {
        cpus   = { log_increase_cpus(2, 2*task.attempt, 1, 2) }
        memory = { check_max( 16.GB * task.attempt, 'memory'  ) }
    }

    withName: COOLER_CLOAD {
        memory = { check_max( 6.GB  * task.attempt, 'memory'  ) }
    }

    withName: COOLER_DUMP {
        memory = { check_max( 100.MB * task.attempt, 'memory'  ) }
    }

    withName: COOLER_ZOOMIFY {
        cpus   = { log_increase_cpus(2, 2*task.attempt, 1, 2) }
        memory = { check_max( (meta.genome_size < 1000000000 ? 16.GB : 24.GB) * task.attempt, 'memory' ) }
    }

    withName: MULTIQC {
        memory = { check_max( 500.MB  * task.attempt, 'memory'  ) }
        time   = { check_max( 1.hour * task.attempt, 'time' ) }
    }

    withName:CUSTOM_DUMPSOFTWAREVERSIONS {
        cache = false
    }

    withName: AGAT_SQSTATBASIC {
        memory = { check_max( 500.MB  * task.attempt, 'memory'  ) }
    }

    withName: AGAT_SPSTATISTICS {
        memory = { check_max( 3.GB  * task.attempt, 'memory'  ) }
    }

    withName: BUSCOPROTEINS {
        memory = { check_max( 4.GB * task.attempt, 'memory'  ) }
        cpus   = { log_increase_cpus(2, 2*task.attempt, 1, 2) }
        time   = { check_max( 2.h * task.attempt, 'time') }
    }

    withName: PRETEXTMAP {
        cpus    = { 4        * task.attempt }
        memory  = { 3.GB     * task.attempt }
        time    = { 1.h      * ( fasta.size() < 4e9 ? 24 : 48 ) * task.attempt }            }

    withName: PRETEXTSNAPSHOT {
        cpus    = { 1        * task.attempt }
        memory  = { 1.GB     * task.attempt }
    }
}
